## flume

#### 1.组成

​	1）source：taildir source ；支持断点续传，多目录 apache1.7新增

​								以前自定义source实现续传
​								flume 有可能产生重复数据，可在Hive数仓过滤
​				    kafka source  ；配合上游kafka使用  实现消峰
​		2）channel ： file channel ；写入磁盘    可靠性高   效率低
​					memory channel ；载入内存   可靠性低   效率高
​					kafka channel ；写入磁盘   可靠性高   比memorychannel + kafka sink 效率高
​					1.6版本新增  
​					实际使用选择 ： 要求高可靠性，与钱相关选file channel ；要求效率高 选memory channel 
​		3）sink  : hdfs sink  使用必须解决小文件问题  ；a. 生成文件大小与hdfs block大小一致，滚动时间   rollcount一般为30min

#### 2.三大器

​	1） 拦截器
​		上游flume ETL拦截器  对读取到flume 的数据进行轻度清洗
​		下游flume 时间戳拦截器  对Maxwell同步的数据替换时间戳
​		自定义拦截器步骤 ： 实现Interceptor接口 ，重写四个方法  初始化方法，单event，多event，关闭流  实现静态内部类Builder   打包上传到flume/lib   在配置文件中拦截器类型声明拦截器全类名$Builder
​	2）选择器
​		channel 选择器 
​		    a.  replicating   默认    把数据发送到下游所有通道
​		    b.  multplexing   自定义选择分流
​	3）监控器
​		ganglia监控器   如果监控到flume尝试提交次数远大于成功次数，说明flume运行状况较差，一般是由于内存不足导致的，通过增大内存解决
​		
​	flume会丢失数据吗？
​	不会，flume有完整的事务机制，source到channel 是事务的，channel 到sink是事务的 ，只有memory channel有可能会，一百个event
​	还有，flume会有数据重复，例如sink发出数据但是没有收到应答，会再次发送，导致数据重复

#### 3.优化

- 处理小文件问题
- 增加内存
- 增加日志服务器

flume只做简单清洗，不做过多的操作，影响效率
flume压力过大增加日志服务器    8g 16g内存 

## Hdoop

#### 	1.hdfs写入流程

​		首先客户端向NameNode发送写入请求，NameNode收到后进行校验 a.文件是否写入合法   b. 请求用户是否有权限写入
​		检验合格后NameNode向客户端回应允许上传，客户端收到应答后会对文件按照blocksize切块，切块完成后客户端会请求上传第一个block  NameNode收到请求会根据网络拓扑距离返回离客户端最近的存放三个副本的DataNode节点地址，客户端收到后会根据网络拓扑距离选择最近的一台节点建立传输通道，依次与三台节点串接，串接的好处是减小客户端的io压力，然后通过fsoutputstream流对象传输数据，最小传输单位是packet，三个副本节点通过串接依次获取数据，最后一个副本节点写入完成相当于完成一次传输，然后继续下一次传输。

#### 2.hdfs读取流程

​		首先客户端向NameNode发送读取请求，NameNode收到请求后进行校验  a.文件是否存在   b. 请求用户是否有权限写入
​		校验完成后NameNode向客户端返回目标文件的元数据信息，其中包含存储目标文件的DataNode位置信息，客户端收到后根据网络拓扑原理选择拓扑距离最近的一个节点建立数据传输通道，通过fsinputstream流对象将数据读取到本地，如果有多个块就多次请求DataNode，直到文件全部下载

#### 3.小文件危害

​		1）每个文件都会产生元数据信息 ，会占用过多NameNode内存
​		2）传输效率低
​		3）元数据过多会使寻址索引效率变低
​		4）小文件在MapReduce计算时会默认为一个切片，每个切片会运行一个maptask，占用大量集群资源

#### 	4.小文件解决方式

​		1）大量小文件在上传hdfs之前先合并成大文件
​		2）MapReduce阶段使用combineTextinputformat和它的切片规则
​		3)  业务处理之前在hdfs上用MapReduce进行合并
​		4）开启Uber模式，实现jvm重用，很少使用

#### 	5.shuffle机制及其优化

​	shuffle阶段是指map方法之后，reduce方法之前的阶段，maptask把数据从map方法处理完之后写入环形缓冲区，数据会根据分区规则进入指定的分区，缓冲区大小默认100m，缓冲区数据达到80%容量后开始溢写，如果数据量大会多次溢写，溢写之前会根据key按字典序进行一次快排，保证每个文件内部都是有序的，溢写完之后进行一次合并，合并的同时会根据分区进行区内归并排序。然后写入磁盘，接下来reducetask从磁盘拉取数据到内存缓冲，如果内存不够就溢写到磁盘，拉取完成后对数据进行归并排序，然后按照key进行分组，最后每一个key对应的values 调用一次reduce方法。

#### 6.yarn工作机制

​	客户端向yarn提交MR任务时，yarnrunner会申请运行一个applicationmaster，由resourcemannager接受处理，resourcemannager负责资源的分配，根据任务计算出所需要的资源，CPU内存等，将这些资源封装成container对象，resourcemannager将任务发送给资源调度器，调度器将任务和容器分配给applicationmaster，有applicationmaster进行二次分配，将任务分解为maptask和reducetask，然后applicationmaster将maptask和reducetask随机分配给空闲的nodemanager执行，执行时，applicationmaster会对nodemanager任务执行情况进行监控，如果nodemanager上的任务执行成功，会吧成功信息发送给applicationmaster和resourcemanager ，然后resourcemanager会对资源进行回收，如果nodemanager上的任务执行失败，会把失败信息发送给applicationmaster和resourcemanager，此时resourcemanager仍然会进行资源回收，由applicationmaster向resourcemanager再次申请资源，applicationmaster会重新将该任务分配到这个nodemanager，直到任务执行成功，默认最多反复执行4次

#### 6.三种调度器的特点

​	FIFO调度器：遵循先进先出原则，任务需要排队，效率低

​	容量调度器：在FIFO单队列基础上增加了多队列的特性，它可以指定资源占比和调节任务的优先级，使用灵活

​    公平调度器：和容量调度器一样是多队列，但是队列中的所有任务在资源充足的情况下可以并行执行	
​	

## 	Linux

​	

#### 	常用命令：

chmod  改变权限

grep 过滤查找

df 查看磁盘使用情况

fdisk 查看分区

top 查看内存

kill 终止进程

find  查找目录或文件

tar 打包

ps 查看系统进程

netstat 显示网络和端口信息

​	

## shell

群起脚本

```shell
#！/bin/bash
if[$ -lt 1]
then
	echo Not Enough Arguenent!
	exit;
fi
case $1 in
"start")
	for i in hadoop102 hadoop103 hadoop104
	do 
		ssh $1 "文件目录"
	done
;;
"stop")
	for i in hadoop102 hadoop103 hadoop104
	do 
		ssh $1 "文件目录"
	done
;;
esac
```

## Zookeeper

#### 第一次启动选举机制

​	  假设共有五台机器，第一台服务器启动时，发起一次选举，服务器会投自己一票，票数不够半数以上，服务器状态保持为looking；第二台机器启动，发起一次选举，服务器1和2分别投自己一票并交换选票信息，服务器1发现服务器2的myid大于自己，会更改选票改投服务器2，此时，服务器1 0 票，服务器2 2 票，都不够半数以上，两台机器都将状态保持为looking；第三台机器启动，发起一次选举，由于myuid最大，服务器1和服务器2都将更改选票改投服务器3，此时，服务器1 0 票，服务器2 0 票，服务器3 3票，已经超过半数，服务器3更改状态为leader，服务器1 2 更改状态为following； 服务器4启动，发起一次选举，此时服务器1，2已经不是looking状态，不会更改选举信息，交换选票信息，此时，服务器3 3票，服务器4 1票，服务器4服从多数，更改选票改投服务器3，并更改状态为following，服务器5与服务器4同理。

#### 非第一次选举机制

- 集群中有leader时

  节点机器重启后尝试发起选举，会被告知已经有leader存在，然后和leader建立连接，并同步状态。

- 集群中无leader时

  当有节点挂掉后，存活的节点会开始选举，依次按照Epoch，zxid，sid的大小选举，Epoch相同比zxid，zxid相同比sid,选出来的节点为leader。

## Hive

#### 1.Hive的组成

​	访问Hive的用户接口

​	托管在MySQL中的元数据

​	存储文件，运行MapReduce的Hadoop

​	驱动器-->SQL解析器，编译器，优化器，执行器



#### 2.Hive与MySQL等关系型数据库的区别

数据存储位置不同：Hive数据存储在HDFS上，数据库数据存储在本地或其他设备

数据更新：Hive不建议数据的改写或添加，数据库可以增改

索引：Hive没有索引，每次扫描所有数据，数据库有索引

执行：Hive底层是MR类型的计算框架，数据库底层是执行引擎

数据规模： Hive支持大规模数据存储和计算，数据库支持的数据量相对较小

#### HQL编译为MR任务流程

HQL进入程序，利用框架定义的语法规则，对HQL进行语法解析，将HQL转换为抽象语法树

遍历抽象语法树，抽象出查询块，遍历查询块，将其转换为操作树，利用优化器对操作树进行优化，遍历操作树，转化为MR任务，将执行计划转换为物理执行计划，使用物理优化器对任务进行物理优化，最后生成最终的执行计划，提交任务到Hadoop集群运行

解析器 --抽象语法树--逻辑执行计划--逻辑执行计划优化--物理执行计划--物理执行计划优化--执行器

#### 3.内部表与外部表的区别

内部表又叫管理表，内部表直接拥有表中数据，在执行删除操作后Hive会删除表以及表中的数据，一般默认创建的是内部表，通常生命周期不需太高的数据可以使用内部表承载，如统计分析用到的中间表等；

外部表不会没有表中数据的拥有权，执行删除操作后会删除表和表的元数据信息，但不会删除表中数据，外部表通常用来承载采集到的原始数据

#### 4.orderby, sortby, distributeby, clusterby的用法

orderby   全局排序

sortby     每个reduce内部排序

distributeby   根据字段将数据分区+排序

clusteby    sortby和distributeby字段相同时可以使用clusteby代替二者功能

#### 5.常用的系统函数有哪些

NVL（字段，要替换的字符）   空字段赋

CASE WHERE THEN ELSE END

CAONCAT_WS(分隔符，字段，字段)

COLLECT_SET(字段)    去重汇总，产生数组类型字段，只能传值基本数据类型字段

EXPLODE(字段)    炸裂函数，将数组集合等类型的字段数据扁平化

RANK()   排名会重复，排序会断

DENSE_RANK()    排名会重复，排序不会断

ROW_NUMBER()  排名会不重复，排序不会断

#### 6.自定义函数的步骤

一、继承Hive的GenericUDF(GenericUDAF,GenericUDTF)类

二、实现类中的方法，并在类中重写需要实现的业务需求

三、上传jar包后在Hive中创建函数

add jar xxx;

create function 函数名 as  jar包全类名

#### 7.怎么理解窗口函数

窗口函数可以将预处理的数据或需要再处理的结果集放入一个容器，等待再处理，其空间大小由放入的数据数目决定，窗口函数可以为每行都返回结果

#### 8.Hive如何优化

1.在处理小数据集时可以临时开启本地模式，省去集群处理流转的过程节省时间

2.在特定的简单查询时可以开启Fetch抓取，不必使用MapReduce计算从而提高查询效率

3.在map阶段join以防止数据倾斜；在大表join大表时做空key过滤，空key转换；

4.分组操作groupby时开启map端聚合，开启负载均衡

5.去重统计是尽量使用groupby➕ count实现，避免使用count(distinct)造成数据倾斜

#### 9.怎样防止数据倾斜

1.分组等聚合操作尽量在map阶段执行，做法是开启map端聚合

2.去重统计是尽量使用groupby➕ count实现，避免使用count(distinct)造成数据倾斜



