我所做的是电商大数据系统，此项目是之前公司自己的产品，公司主要通过该系统监测电商业务的每日交易数据，通过一定的指标计算，获取各种交易相关的综合数据，供业务部门，管理部门分析决策使用。

​	此项目采用分布式，高可用的大数据系统框架，基于成本考虑，公司采用的是Apache生态的大数据平台

数据采集

  我们的数据主要两个部分，一个是javaEE产生的业务数据，一个是通过前端埋点产生的用户行为数据。这两部分数据都是通过Nginx负载均衡打到数据所对应的服务器中。因为我们的数据量比较大，所以部署了多台服务器。
  那么接下来我就先给您介绍一下日志数据这条线。日志数据通过Nginx打到日志服务器中之后，保存日志数据保存了30天，主要是因为防止后续的任何一个步骤出问题，都能找到最原始的数据的备份。主要是因为在大数据的场景下，数据是最重要的，磁盘相对较廉价。

用户行为数据发送到hadoop集群
      接下来就是将采集的数据打到Hadoop中，其实我们直接用flume发送数据到hadoop集群中是完全没有问题的。但是我们考虑到以后可能还会做实时数仓，所以出于这方面考虑，我们在中间加了一个kafka，起到了一个消峰缓存的作用，离线和实时都能共用。
flume
        flume的组成有source channel sink三部分。在最开始的时候我们用的flume是比较低的版本，那么这个版本的source是没有办法实现断点续传的功能的，我们是自定义了一个source，实现了断点续传的功能。
        在之后我们升级了flume的版本，升级到了1.9，这个版本的taildirsource是支持了断点续传的功能了，其实taildirsource在1.7的版本就已经有了，只不我们到了1.9之后才用。
        对于channel，我们本打算用kafkachannel，但是在1.6版本时，kafkachannel它是有bug的，不管你的参数怎么设置，数据始终带着header头，那么带着这个header头的话，后续还需要进行清洗操作，那么这样计算成本就比较大。我们在1.6版本用的是memorychannel+kafkasink，因为传输的是日志数据，丢几条数据对整体来说是没有关系的。之后使用的1.9版本这个问题就已经解决了。使用kafkachannel比我们之前使用的memorychannel+kafkasink是快很多的。
        在flume这块呢，我们还用了一个拦截器，这个拦截器的作用呢，主要是清洗掉不完整的json字符串数据，减少传输的数据量。这里没有进行复杂的计算或者判断的原因主要是因为flume其实就是一个管道，如果在这里进行太多的业务逻辑，会容易出现数据的阻塞，效率低下，所以我们这块是做的比较简单的数据清洗。
        （拦截器）那么提到拦截器呢，其实自定义一个拦截器是比较简单的，定义一个类，实现interceptor接口，重写里面的四个方法，初始化、关闭、单event（public Event intercept）多Event（public List<Event> intercept），同时呢再写一个静态内部类Builder，打包上传到flume的lib包下，在配置文件中，全类名加上$builder符就可以使用了。
        （选择器）这里我还使用了选择器，选择器主要使用的是默认的replicating选择器，因为我在kafka中只放了一个日志的topic，那么就不需要multiplexing进行多通道的选择，直接replicating选择器就可以了。
        （监控器）我们这里还使用了监控器，叫ganglia监控器，监控器主要监控的是source到channel之间put事务的重试，和channel到sink的take事务的重试，他们都有一个尝试提交的次数和成功提交的次数，如果尝试提交的次数远远大于成功提交的次数的话，就说明flume运行的不是特别稳定，这时就需要调整flume的内存，将flume的内存调整到4-6G（flume.env配置文件）左右就可以了。
        （kafka）那么这样呢，数据就打到了kafka中，那么在使用Kafka之前呢，我们也详细的调研了kafka这个架构。比如kafka的组成有生产者、broker、消费者、zk，我们的kafka传输的数据量不是很大，一秒钟平均1M左右，峰值能达到20M/s左右。但是在使用kafka的过程中我们遇到了很多问题，比如kafka挂了，丢了，重复，积压，乱序，
        （挂了）如果kafka挂了的话一般情况下重启就好了，那如果是kafka某个节点误删了，那么就需要使用kafka服役新节点的操作再服役一个节点，在这里需要注意的是，kafka的备份一定要>=2，不然真的挂了一台节点，那么就会导致数据丢失了。

（丢了）在一个呢，就是kafka的数据丢失问题，关于数据丢失问题主要看你的acks的配置，acks有0 1 -1三个应答机制，
        ack等于0就是kafka发送过来数据之后就不管了，在企业中是不能使用的
        acks等于1，是生产者发送过来数据，leader进行应答
        acks等于-1是在isr队列中的全部follower都收到之后进行应答，但是并不是acks=-1就数据完全不丢失，不丢失的前提是在isr队列中的副本数>=2同时设置的副本数也得>=2，否则acks=-1容易退化成acks=1的情况。
        因为我们在这里传输的数据只是日志，丢一点没关系，所以我们选择的acks=1。
        
（数据重复）开启幂等性+事务 ，幂等性默认开启，幂等性通过pid，分区号，序列号来判断数据是否重复，幂等性只能保证单会话内不重复，因为重启后会重新生成pid,所以需要开启事务，事务就是把offset保存在系统主题中，利用五个API实现事务（初始化，启动，停止，提交，offset）
        （数据积压）我们也遇到了数据积压的情况，主要是因为kafka中数据保存的时间是有限的，我们后来由7天改为3天，如果我们处理数据不及时，就会导致kafka中数据的积压，那么就需要增加kafka的分区数，同时要求下游的消费者增加cpu核数来解决这个问题，同时呢，在消费者拉取数据的时候有一个batchsize默认是500条，可以提高到1000条或2000条可以加大处理速度
        （kafka乱序）还有就是kafka的乱序问题，kafka是分区内有序，分区间无序，要想是kafka单分区有序，如果是kafka1.0之前，只需要将flight参数设置为1就行，那么在1.0以后的版本中如果没有开启幂等性，只需要设置flight参数为1，在开启幂等性的情况下，需要将参数设置为<=5，会自动的帮你处理，处理的原因是因为生产端会帮你缓存5个request请求，在服务器端也会帮你缓存5个request请求的元数据，然后进行排序，保证数据的有序
        （高效读写）kafka其实非常厉害，能够做到高校读写，主要是因为kafka里面是支持集群和多分区的配置，同时segment里面存储了索引，采用稀疏索引这种方式，效率来说是比较高一些的，同时呢，kafka还是顺序读写，能达到600M/s，完全可以匹配固态硬盘读写速度。另一个是它采用零拷贝和页缓存这种技术，数据是直接发送给Linux系统，让linux系统的页缓存来维持这个数据是否持久化到磁盘，同时呢，在应用层不需要读取任何的数据，所有的操作都是在页缓存以及磁盘进行操作，所以速度的是非常快的
        （提高吞吐量）在kafka中还遇到了如何提高吞吐量的问题，一个是从生产者到集群以及从集群到消费者都需要提高吞吐量，生产者到集群提高吞吐量有四个参数，对应的一个是批大小，默认是16k，可以把它适当提高，还有一个是lingger.ms提高到5-100ms，对应的32m缓存，可以提高到64m，还有就是可以采用压缩，可以使用snappy压缩方式。那消费者端可以提高每次拉取的上限，默认是50m，可以调高到60-70m，每批次拉取的500条可以提高到1000-2000条，还可以增加分区数，来提高kafka的吞吐量。
        （单条日志）在kafka使用时，遇到一个问题，就是传输过来的日志大于1M，直接导致了kafka的卡死，我就分析了一下，kafka工作的原理，主要的原因就是生产者发送到broker的单条数据不能大于1m，broker接收的单条数据也不能大于1m，还有就是在leader和follower同步之间，数据也不能大于1m，大于1m的话都会卡死，所以我就把这些参数调高到了2m，同时也要跟上游的业务人员进行沟通，不要让他产生的日志过大，一般控制在1k左右就可以。
        （zookeeper）然后就是采用zookeeper做分布式协调，zookeeper是部署了三台，主要是因为zookeeper的选举机制是半数机制，所以安装奇数台。
        （hadoop）那么再往后，就是准备将kafka的数据拷贝到hadoop当中，或者做实时同步，那么这个地方其实我们有很多种方式可以将数据写入到Hadoop中，比如有spark flink Java 程序写一个消费者一个hdfs的上传完全可以实现这个功能，但是我们考虑到还是flume相对来说比较稳点，而且不用写代码，直接一个配置就完事了，还有就是我们前面用了flume，对这个技术比较了解。那么这个flume使用的source是kafkasource，channel使用的是memorychannel，因为传输的是日志数据，主要考虑的是效率，所以没有必要那么可靠，对应的sink是hdfssink，在用hdfssink 的时候遇到了一些问题，配好之后直接在hdfs上产生了大量小文件，我查阅了对应相关手册，发现有对应的参数可以解决对应的问题，将滚动文件大小改为128M，发现只改这一个参数是不行的，因为如果文件迟迟没有达到128M，所以一直不会滚动，所以需要配置一个时间，30min，如果超过30min，也会滚动。这里也用到了拦截器，这个拦截器的作用主要是时间戳拦截器，解决零点漂移的问题。如果在前一级日志产生的时间是23：59，那么传输到当前这个flume时，它的hdfssink默认的是读取的当前的系统时间，比如说已经到了00：10，那么这条数据就会分到下一天的数据中，那么之后还需要把这个数据处理完之后添加到前一天的分区中，需要进行二次处理，比较麻烦，直接使用拦截器将日志时间获取到，赋值hdfssink，直接就能写到当前时间对应的分区中。
        （hadoop小文件）那么既然提到hadoop的小文件，那么就需要解决这个问题，主要是采用har归档、conmbineTextInPutFormat、JVM重用。那么har归档就是将大量的小文件整合到一起形成一个文件，其实是减少了NN的压力。还有就是在计算的时候，因为默认切片规则是按照每一个文件进行切片，所以我们可以使用conmbineTextInPutFormat把所有的文件放在一起统一的进行切片，最终减少切片的个数，从而减少了maptask数，减少了集群的资源。还有就是JVM重用，在有大量的小文件时，jvm开关的时间和计算的时间处在了同一个量级，jvm重用可以节省开关的时间，同一个job中的不同的maptask可以公用一个jvm，加快处理的速度。
业务数据
        （业务数据）然后就是处理业务数据，业务数据我们采用的增量的方式进行处理，但是在第一天的时候，在mysql中可能会有一些存量，那么第一次同步的时候我们采用的是DataX帮我们从mysql中同步到hdfs中，只有第一次同步的时候需要用。除了DataX还可以使用sqoop。在使用datax时也遇到了一些问题，比如在mysql中的空值存储的就是null，而hdfs中存储的数据要给hive使用，这里存储的空值是\N，这个就涉及到了转换的问题，所以我们在建表时\N用null进行处理。还有就是DataX从mysql导入到HDFS可以控制速度，如果性能比较低的话，可以改变它对应的内存。另一方面就是实时的同步mysql中的数据到HDFS中，我们采用的是maxwell实时的监控mysql的binlog，进行实时同步，除了maxwell还可以使用cannel、flinkCDC，选择maxwell的原因主要是因为它能实现断点续传，配置起来也比较简单实用。其实maxwell也可以使用全量同步，但是为什么没有用它来第一天的全量同步，主要是担心mysql中的数据量比较大，bootstrapt同步的比较慢

hive on spark
        那么数据传过来之后，我们就开始搭建数仓，搭建数仓采用的是hive on spark的方式，主要是因为hive的生态比spark的生态要好一些，主要体现在元数据管理，还有就是权限管理，配合使用，hive比较全面，如果不考虑这些生态的话，可以完全使用sparkSQL。
        （hive组成）在使用hive之前，也了解了一些它的工作原理。比如hive 的组成，有客户端，元数据（元数据默认保存在derby数据库，但是derby数据库只能被一个客户端访问，所以我们保存在了Mysql数据库中，能够提供多用户访问），四个器（解析器 编译器 优化器 执行器），MR引擎我们给他替换成对应的spark引擎，比mr引擎速度快很多，底层存储数据的时候就是HDFS。
        （创建表）在hive中创建表，主要都是创建的外部表，主要原因就是因为在删除数据的时候，内部表是将元数据和原始数据都删除，而外部表只删除元数据，原始数据不删除。
        （4个by）在使用过程中还使用到了4个by，order by sort by distribute by cluster by   orderby几乎不使用，因为它是全局使用，他是将所有的数据放到一个reduce中处理，很容易出现oom。在企业中用的比较多的是sort by + distibute by 排序+分区，分区内排序，cluster by 是在ort by 和distribute by的字段相同的时候可以使用cluster by 代替。
        （系统函数）另外在使用的时候用到了大量的系统函数date_add、date_sub函数（加减日期）next_day函数（周指标相关）date_format函数（根据格式整理日期）last_day函数（求当月最后一天日期）CONCAT、CONCAT_WS、COLLECT_SETEXPLODE get_json_object解析json函数NVL（表达式1，表达式2）来帮我们解析，但是这些函数也不能帮我们解决所有的问题，所以我们还需要进行自定函数进行解析，比如UDF、UDTF、UDAF进行解决。那我们项目中就用到了UDF和UDTF，那么实现UDF也非常简单，自定义UDF：继承UDF，重写evaluate方法，自定义UDTF：继承自GenericUDTF，重写3个方法：initialize（自定义输出的列名和类型），process（将结果返回forward(result)），close，需要将自定义函数打包上传到HDFS路径上，同时在Hive客户端中进行注册使用，使用自定义函数的还有一个原因是可以自己埋点Log打印日志，出错或者数据异常，方便调试。另一方面，引入第三方jar包时，也需要使用自定义函数。还用到了大量的开窗函数，需要在里面统计topN。
        （优化）之后我们在hive使用中做了大量优化，在使用mapjoin的时候默认的是打开的就不要关闭了，尤其是大小表join的时候，另一个就是提前进行行列过滤，先进行where之后再join，创建分区表防止全表扫描，可以创建分桶表，主要处理复杂逻辑，对数据不是特别清楚，提前对key值采样，避免数据倾斜，还有就是处理小文件的方法JVM重用，使用combineHiveInputformat方式改变切片规则，还有采用merge，merge的功能是maponly是默认打开的，mr任务是关闭的，需要手动打开，它的功能就是在执行一个任务的时候会生成大量的小文件，它可以将这些小文件进行合并，小于16M的文件合并到256M进行处理。还可以采用map输出的时候采用压缩snappy，列数存储加快查询速度，可以采用combiner提前进行聚合，当然有条件不能影响最终的业务逻辑，合理的设置map个数和reduce个数，reduce个数可以直接set，多个key的话可以直接set，单key的话没有必要，map的个数是根据切片的个数决定的，可以合理的设置切片的大小（控制0和long的最大值就可以控制切片的大小）
        （数据倾斜）在使用hive的过程中也遇到了数据倾斜的问题，往往是发生在空值，如果遇到空值，可以将空值过滤掉，如果不能过滤的话，在空值后面加上随机数，进行打散处理。增加reduce的个数。检查表语表join的时候字段的数据类型是否一致。
数仓构建
        （数仓建模）那么接下来就是正式的数仓建模，在开始数仓建模之前，需要大量的数仓理论，我们采用的是维度建模，星星型模型（事实表周围一级维度） 雪花模型（事实表周围多级维度）星座模型（多个事实表），这里提到了事实和维度，事实表分为事务型事实表、周期型快照事实表、累积型快照事实表，事实表的同步策略就是增量同步，当然有特殊的，未来有统计库存的时候，统计的是全量。维度表的特点只是记录描述信息，没有度量值，维度表的同步策略是全量同步，当然也有特殊的，是用户表，采用的是拉链表。
        （建模）这些都完事之后，我们就开始正式的建模，建模的步骤有数据调研、明确数据域、（业务驱动）构建业务总线矩阵、维度建模、（需求驱动）明确统计指标、宽表聚合，然后进行开发使用
        （ods）接下来就是真正的数仓建模，ods层就是保留原始数据，起到一个备份作用，第二件事创建了分区表，防止全表扫描，第三件事是采用了压缩（gzip），减少磁盘的空间。
        （dim）dim层主要处理的是相关维度，主要是维度的整合。将商品相关的品类 一级分类 二级分类 三级分类 退化成维度表  活动相关的优惠券信息 活动信息 退化成活动维度表，除了用户表采用的是拉链表，主要是因为用户表是缓慢增长的表，可能一周变化一次，一个月变化一次，都有可能。如果每天全量同步有太多的重复数据，使用拉链表，将用户表进行初始化，加上状态的开始时间和结束时间，第二天获取新增及变化的数据直接fulljoin，获取到全量的最新的数据，同时还有过期的历史数据
        （dwd）接下来是dwd层，dwd层就是标准的建模，主要是以事务型事实表为主，先考虑事务型事实表能不能解决所有需求。那么事务型事实表的建表规则第一步是选择业务过程 选择感兴趣的业务过程，就是未来统计业务需求所需要的业务过程；第二步就是声明粒度，就是定义一行数据代表什么含义，可以代表一次下单，这样的，最好是选择最细粒度，以应对各种不同的需求；第三步就是确定维度，其实就是确定每列代表什么，发生这个业务过程的时间地点那个商品使用什么优惠券等等统计过来；第四步就是确定事实，就是确定事实表的度量值，就是可累加的值，比如次数 金额 件数 个数 等等。但是事务型事实表不能解决所有的问题，比如一些存量型指标，连续状态的指标，和多事实表的join操作都不适合，对于存量型这种指标的话使用周期型快照事实表，每天进行统计；那么多事实表join，比如下单的业务流程中每个业务过程所耗时间的平均值，需要使用累积型快照事实表，因为周期型快照事实表是将业务流程中的每个业务过程中的时间字段都存在一张表中，事实就是每个业务过程中的度量值。累积型快照事实表我们没有做，因为业务需求不需要
        （指标体系的建设）下面就是指标体系的建设，指标体系分为原子指标、派生指标和衍生指标，原子指标就是业务过程的度量值的计算逻辑；派生指标就是原子指标+统计周期+业务限定+统计粒度；衍生指标就是多个派生指标通过逻辑运算复合成的，比如计算一些比率、比例型的指标。以每天各个省份华为手机的交易总额为例，交易总额是原子指标，业务过程是下单，度量值是交易金额，聚合逻辑是求和（sum），统计周期是每天，统计粒度是各省份，业务限定是华为手机这个品牌。像这样拆分完之后我们要找共同的业务过程，共同的统计周期，共同的统计粒度把他们放在一张表中，实现复用，这样就组成了dws层。
        （ADS）那么ADS层呢，就是统计流转G复活相关的一些指标----能手写（七天内连续三天，一分钟内在线人数……）
        （即席查询）通过presto，快速的统计相关的指标
        （导入MySQL）使用DataX往MySql导入，这里的DataX也需要注意空值问题，需要加上对应的参数解决问题，同时还要注意，如果ADS层里面有空文件，在写脚本的时候应该将空文件过滤掉，否则会报错。
        （可视化）通过superset连接Mysql进行可视化。
        （任务调度）使用DS进行任务调度，在使用DS时，也遇到了指标挂了的情况，一般我们是00：30分开始执行，那如果挂了的时候呢，会有故障报警，发短信打电话微信钉钉都可以，这种情况出现呢一般都是远程连接服务器进行重试，如果这样不行的需要检查是不是发生数据倾斜，如果数据倾斜需要把任务停掉，第二天把数据倾斜解决掉再重新启动程序。如果是DS服务挂了的话，尝试重启，如果重启起不来，需要检查一下内存，jmap -heap + 进程号 检查一下内存是什么情况，如果不够的话给他多分配一些内存。
        （元数据管理）使用Atlas（版本2.1）进行元数据管理，因为我们数据越来越多，如果中间有哪一个任务中间异常挂了，那么会影响哪一个指标的输出，可以通过Atlas进行解决。
        （权限管理）Ranger权限管理，可以说正在研发，也可以说别人正在做，这个坑比较多，不要说做过
        （质量管理）使用python+shell脚本实现的数据质量监控，监控每一层没一张表的空值重复值以及ADS层日活新增转化率的快速上升快速下降，都可以通过superset进行展示，通过睿象云进行报警
        （监控）使用Zabbix+Grafana进行整个集群进程的监控任何一个进程挂掉之后都可以捕捉到，进行打电话，发短信的相关报警
