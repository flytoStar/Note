### 基本情况

食行生鲜是一个生鲜蔬菜食品B2C网购平台通过线上预订线下社区自助提货的采购模式，食行生鲜提供的产品包括蔬菜豆菇、水果、肉禽蛋、水产海鲜、米面粮油、休闲食品等8000种，平台无条件免配送费

江苏随易信息科技有限公司 

苏州食行生鲜电子商务有限公司 
苏州高新区竹园路209号  太湖， 阳澄湖， 寒山寺
公司两百多人，研发部 大数据组11人，我去的时候是6人，实时6人，Java15人 ，前端3人，安卓ios2人，测试2人，运维2人，共37人，Leader王永

工作内容：领导有报表需求就做报表，没有就对数仓进行维护和对一些不满足需求的表增加一些字段，还有就是有新的指标就开会讨论然后做新的指标



苏州1号线 木渎站-->汾湖路站  苏园小区  房价25000

春秋 番茄，青椒，生菜，五花肉
夏天 莲藕，黄瓜，玉米
冬季 蘑菇，白菜，土豆，五花肉

200万日活  订单15-20万，交易额7 800万左右

自我介绍，离职原因

面试官你好，我叫李志星，本科学历，毕业于河南工学院，最近三年一直在苏州食行生鲜电子商务有限公司从事数仓开发的工作，在公司担任大数据开发工程师，公司的主要业务是生鲜蔬菜网购平台，通过线上预订，线下自助提货的模式运营，我在上家公司主要做了离线数据仓库系统，用户画像系统，实时数据仓库系统三个项目。经过三年的工作，在数仓开发和构建方面，也有了一定的开发经验和技术积累，最近也了解了贵公司的岗位要求和技术需求，我认为目前我的开发经验和技术水平可以满足贵公司的要求，很期待能够加入贵公司，也希望面试官能给我这样一个机会。



离职一周左右，面了五家，手里有一份offer正在考虑



不过我不完全根据薪资考虑offer，这些在面试之后都是可以谈的，再加上不太了解咱公司的薪资结构，所以面试之后都可以再做调整



A4纸  红笔黑笔  简历  文件袋



1.修改简历权限为均不可见
2.屏蔽企业，点击
工作描述是岗位职责+专业技能



问面试官的问题：
技术：
1.目前公司使用什么技术栈？某某技术没接触过，是否给时间学习？
2.主要做的业务是哪个方向？
3.目前人员架构是什么？我主要的工作内容是什么？
4.我能给公司解决什么样的问题？
人事：
1.公司1-3年内是否有人才培养计划？
2.转正的考核机制是什么？
3.公司的企业文化是什么？一年团建几次？

PMP
ACP



**数据量 **
日活200万   *100  ==  2亿  约200G    2300条/s  2M/s   峰值20M/s
ods  gzip压缩                 	   20G
dim+dwd  snappy压缩           20G
dws  为了快速计算不压缩       100G
      副本 * 3  == 140G*3==420G
  420G**180天== 74T
    留30%余量 106T

业务数据每日下单20万 2G
  ods+dim+dwd==6G
  3副本 * 6G == 18G
  18G * 180天 == 3T
  留30%余量  4T

  kafka两副本  400G
保存3天      400G*3==1.2T 按2T

总数据量 2 + 4 + 106 == 112T

8 * 14== 112T

20核物理CPU  40线程  * 14 = 560线程    100--200个指标

128G * 14台 == 1792G
14台服务器
1400G --> 175G数据

**架构配置**

kafka        5台
zk            3台
flume       3台
hive        14台
spark       14台
flink         14台
datax       14台
maxwell     1台
MySQL       1台
DS          14台
Redis       1台
clickhouse  1台
HBASE       3台



**SQL正确性和数据准确性**

从生产环境抓取一部分数据，数据有多少你是知道的，运算完毕看看是否符合我的预期

#### 数据质量管理

通过Shell命令和Hive脚本的方式，通过验证增量数据的记录数、全表空值记录数、全表记录数、全表重复值记录数是否在合理的范围之内，以及验证数据来源表和目标表一致性，确定当日的数据是否符合健康标准，达到数据质量的监控与管理。

使用hive+shell脚本实现的数据质量监控，监控每一层每一张表的空值重复值是否在合理范围内以及ADS层日活新增转化率的快速上升快速下降，都可以通过superset进行展示，通过睿象云进行报警

**维度建模理论**

维度建模是一种将大量数据结构化的设计手段，包含维度和事实，它不像ER模型目的是消除冗余数据，维度建模是面向分析，最终目的是提高查询性能，所以会增加数据冗余，并且违反三范式。
维度建模也是重点关注让用户快速完成需求分析且让复杂查询及时响应，维度建模一般可以分为三种：

- 星型模型
- 雪花模型
- 星座模型


其中最常用的其实是星型模型

优点

- 缩小了事实表的大小。
- 便于维度的管理和维护
- 维度表可以为多个事实表重用，以减少重复工作。

**每层那张表数据量最大**
ods 日志表       35T
dim 商品表        10G
dwd 下单事实表   35G
dws 用户粒度订单历史至今汇总表   45G
**每层多少表**
ods  34
dim  7
dwd  32
dws  37
ads  平时103  活动135

#### Hashmap底层原理

HashMap底层就是数组+链表+红黑树结构，新建一个HashMap的时候，就会初始化一个数组。Entry就是数组中的元素，每个Entry其实就是一个key-value的键值对，它持有一个指向下一个元素的引用，这就构成了链表，当链表长度大于等于8时会转换为红黑树，HashMap底层将key-value当成一个整体来处理，这个整体就是一个Entry对象。HashMap底层采用一个Entry[ ]数组来保存所有的key-value键值对，当需要存储一个Entry对象时，会根据hash算法来决定在其数组中的位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry对象时，也会根据hash算法找到其在数组中的存储位置， 在根据equals方法从该位置上的链表中取出Entry;

扩容必须满足两个条件

- 存放新值的时候当前已有元素必须大于阈值；
- 存放新值的时候当前存放数据发生hash碰撞（当前key计算的hash值计算出的数组索引位置已经存在值）

#### OLAP和OLTP

- OLTP

  OLTP系统强调数据库内存效率，强调事务性；

  如MySQL，Oracel

- OLAP

  OLAP系统则强调数据分析

  如hive，clickhouse

  
  
  
  
  ![image-20220916165441761](C:\Users\flyStar\AppData\Roaming\Typora\typora-user-images\image-20220916165441761.png)
  
  
  
  
  
  
  
  #### 集群监控
  
  Prometheus&Grafana监控  睿象云



#### 数据治理

- 元数据管理

  使用Atlas构建资产目录，形成数据字典，Atlas提供了一个Hive元数据导入的脚本，直接执行该脚本，即可完成Hive元数据的初次全量导入。Hive元数据的增量同步，无需人为干预，只要Hive中的元数据发生变化（执行DDL语句），Hive Hook就会将元数据的变动通知Atlas。除此之外，Atlas还会根据DML语句获取数据之间的血缘关系。

  - 血缘依赖

    通过Atlas查看Hive元数据，即可发现血缘依赖图，可以看到表与表的血缘关系，字段和字段之间的血缘关系

- 主数据管理

  主数据就是各个系统共享的数据，它描述核心业务的实体，例如员工、组织机构、客户等。可以提高企业数据质量和数据资产价值的关键因素

- 数据质量管理

  使用hive+shell脚本实现的数据质量监控，监控每一层每一张表的空值重复值是否在合理范围内以及ADS层日活新增转化率的快速上升快速下降，都可以通过superset进行展示，通过睿象云进行报警，通过shell脚本调用hive，检验当日分区增加的记录数量和全表记录数量是否在合理的范围之内

- 数据质量评价

资产健康度量化模型。

根据数据资产健康管理的关键因素，明确量化积分规则。根据数据基础信息完整度、数据存储和数据计算健康度、数据质量监控规则合理性等，完整计算数据资产健康分。

￮ 健康分采用百分制，100最高，0分最低；

￮ 健康度以表为最细粒度，每个表都有一个健康分；

 





1. ORC是列式存储，有多种文件压缩方式，并且有着很高的压缩比。
2. 文件是可切分（Split）的。因此，在Hive中使用ORC作为表的文件存储格式，不仅节省HDFS存储资源，查询任务的输入数据量减少，使用的MapTask也就减少了。
3. 提供了多种索引，row group index、bloom filter index。
4. ORC可以支持复杂的数据结构（比如Map等）



**分区表：**  优点是：提高查询效率    要求是：分区字段绝对不能出现在表已有的字段内。

**分桶表：**  优点是：提高join效率和用于数据取样。   要求是：分桶字段必须出现在表已有的字段内







共享文档，指标中心管理指标
产品经理创建指标，分析指标，

数据质量监控
强规则 脚本再跑一次，结果异常就停止任务阻断下游
弱规则 脚本再跑一次，结果异常不停止任务有警告第二天解决


产品提需求，后端（后端提出表里需要什么数据什么字段），联调后端有问题就找我，没问题就交给QA，没问题就上线


简单的查询那种自己可以测，复杂的指标无法溯源由QA测

攻坚一周左右完成





#### Clickhouse

**遇到的问题及优化**

Clickhouse内存是一定的，内存不够了会杀任务，增加内存解决

本身不支持幂等性，在实现flink和clickhouse的端到端一致性的时候，使用replacingmergetree表引擎来实现去重达到幂等的效果，自动去重时间不确定

使用optimize手动去重，每周一手动去重

在去重前使用final查询效率低，可以增加线程数提高查询效率



**优点：**

按向量处理查询效率高

写入速度高

列式存储聚合统计快

具有丰富的表引擎



**缺点：**

不支持事务

不支持高并发，qps100左右





clickhouse删除是做失效标记，当触发分区合并之后才会真正删除旧数据



#### 生产经验

项目进度

**扮演的角色锁了哪些事情**

离线：采集通道环境搭建，数仓分层建模，指标计算，数仓维护或故障分析（小文件问题解决，数据倾斜问题解决）
实时：运行环境搭建，数仓分层建模，指标计算，性能优化（反压问题，数据倾斜问题，缓存数据库一致性问题，分区没数据）
画像：标签制作，通用任务开发，数据流转任务开发

**有哪些人参与进来**

产品经理，项目经理，前后端，测试

**遇到的问题和最大的成长**

旁路缓存异步io

项目周期

离线从环境搭建到初期指标计算完上线大约11个月左右
实时从环境搭建到初期指标计算完成上线大约5个月左右

**攻坚周期**

反压解决，一致性问题解决，20天左右

**对数仓的理解：**数仓首先是仓库，存储数据的仓库，也是一个可以反映历史变化的数据集合，其次在维度建模后我们可以把数据分门别类的保存在不同的数据层中，便于数据的应用和管理，每一层数据都有不同的用途





Linux命令   
拉链表
seondrednamenode
habse  为什么选择   
1.对很多字段的宽表支持比较好
2.扩展性比较强，可以增加新的reginonServer ，HBASE基于hdfs，可以存储海量数据
3.同事对HBASE比较熟悉
二级索引
将索引列拼接上原表的rowkey作为索引表的索引，提高检索效率
rowkey
唯一原则，设计时必须保证唯一
长度原则，一般设计rowkey不超过16字节，不然会降低检索效率
散列原则，rowkey应均匀的分布在各个region上
反转时间戳常用
yarn资源配置
每个NM给容器分配的总内存为总内存减去其他服务所需的内存
分配给容器的核数为内存的1/4
每个容器可使用的最大内存为16G


目标日期大于等于开始日期，小于等于结束日期


项目进度

扮演的角色做了哪些事情
离线：采集通道环境搭建，数仓分层建模，指标计算，数仓维护或故障分析（小文件问题解决，数据倾斜问题解决）
实时：运行环境搭建，数仓分层建模，指标计算，性能优化（反压问题，数据倾斜问题，缓存数据库一致性问题，分区没数据）
画像：标签制作，通用任务开发，数据流转任务开发
有哪些人参与进来，
产品经理，项目经理，后端，测试
遇到的问题和最大的成长，
旁路缓存异步io
项目周期，
离线从环境搭建到初期指标计算完上线大约11个月左右
实时从环境搭建到初期指标计算完成上线大约5个月左右
攻坚周期
反压解决，一致性问题解决，20天左右

工作流程
项目经理提供需求文档，弄清楚需求怎么定义的，然后需求评估，项目经理把前端后端大数据集合开会，明确数据格式，数据类型，字段等，确保每个人理解的一致，开发完成后联调，我们确保数据的准确性，前后端保障数据源和BI不出问题，最后测试对整个系统进行测试，测试通过后再上线

每天做什么
有新的指标就开会讨论然后做新的指标，没有就对数仓进行维护故障分析和对一些不满足需求的表增加一些字段，还有一些临时任务

对数仓的理解：数仓首先是仓库，存储数据的仓库，也是一个可以反映历史变化的数据集合，其次在维度建模后我们可以把数据分门别类的保存在不同的数据层中，便于数据的应用和管理，每一层数据都有不同的用途





遇到的问题
离线：hive小文件问题，数据倾斜问题，hdfs小文件问题，零点漂移问题，空值无法解析问题
实时：反压问题，缓存数据库一致性问题，数据倾斜问题，大状态，分区没数据，watermark不传递，窗口不能创建

**最近学了什么**
数据湖：能处理所哟与类型的数据，结构化，非结构化，半结构化，可以根据海量数据挖掘出规律，数据湖也拥有很强的计算能力去处理数据
Doris：kv类型数据库，列式存储，按向量查询，查询执行效率高，可以直接对接kafka，支持自定义UDF

相较于ck它支持海量并发查询，支持事务

**数据质量监控**

通过hive和shell实现的数据质量监控，监控每一层每张表的空值重复值是否在合理范围内，ads层的日活新增转化率的快速上升或下降，用superset做可视化展示，用睿象云告警，
适应shell调用hive，监控当日分区增加的记录数和全表记录数是否在合理范围内
**未来规划**
通过不断的学习来继续沉淀自己的技术，在做好自己分内的同时也希望能多多接触公司的各种业务，提高自己的能力，能够负责更多的方面

**各角色之间的交互**
产品提需求给项目经理，项目经理找前后端大数据开会评估，能做就排期确认工期，做完联调，前后端负责数据源个可视化不出问题，我们保证数据的准确性

**期望下一份工作**
首先是团队氛围，像之前公司，无论谁遇到问题，我们都会一起去讨论研究解决方案，一方面能够增加团队凝聚力，另一方面能够提高每个人的解决问题的能力，
其次是公司业务方面，公司是否有更多的业务拓展，去尝试新的技术，一方面我能得到能力上的成长，另一方面也能为公司解决更多的问题实现自己的价值
