## 离线数仓介绍

​	做这个项目的主要目的是公司为了监控电商业务的每日交易数据，通过一定的指标计算，比如用户留存，转化率，GMV，复活率，日活等，获取各种交易相关的综合数据，供业务部门，管理部门分析决策使用。

​	首先在拿到业务数据后进行**数据调研**，在熟悉了业务过程和数据后，将业务过程和数据对应起来，然后和业务人员核实自己的理解；然后和产品经理确认需求，进行指标分析，查看指标所需的业务过程和维度是否充足

​	在数据调研后，发现有两条业务线，一条是前端埋点产生的数据保存到日志服务器，使用flume采集日志服务器的日志文件变动，可以直接将数据打到hdfs，但是考虑到有活动时数据量猛增，以及日后可能会搭建实时数仓，所以部署了kafka，在采集数据时起到消峰缓冲的作用，也为日后搭建实时数仓做了提前准备，数据到kafak后，为了简单可靠，又部署了flume将数据写入hdfs；

​	另一条线是由Javaee后台产生的业务数据保存在MySQL，全量数据通过datax把数据同步到hdfs，增量数据通过Maxwell将数据同步到kafka，然后由下游的flume写入hdfs；在搭建采集通道的过程中，也遇到了一些问题，直接使用hdfs sink时，会在hdfs产生大量小文件，在存储和计算时都会有很大影响，我通过在flume配置文件中设置文件滚动大小和滚动时间后解决；还有采集时会出现零点漂移问题（例如在前一天11：59产生了一批数据，进入采集通道后，可能会在中间出现了延迟，在到达hdfs sink时，已经是第二天了，hdfs sink会按照本地时间把这批数据写入当天分区），我们通过在flume配置时间戳拦截器解决

​		接下来是**明确数据域**，就是把数据纵向划分，把数据分类，便于数据的管理和应用，我们把数据分了五个域，交易域，工具域，用户域，互动域，流量域；

交易域是加购，下单，支付，退单，退款等相关数据；

工具域是优惠券领取，优惠券使用的相关数据

用户域是注册，登录相关数据

互动域是收藏，评论相关数据

流量域是启动，曝光，页面，动作，错误

​		然后**构建业务总线矩阵**，业务总线矩阵中一行是一个业务过程，一列是一个维度，行和列的交点表示二者的关系，我们就在这个总线矩阵中描述二者的关系一行就是一张事务型事实表，一列是一张维度表

之后开始建模，首先ods层，这一层的主要就是

​	保持数据原貌，不做任何修改，起到备份的作用
2. 创建分区表，避免后续查询全表扫描
3. 使用gzip压缩，减少磁盘占用

**DIM层** 主要存放维度表，将多张表进行维度整合形成一张维度表

​	活动信息表+活动规则表---->活动维度表

​	省份表+地区表---->地区维度表

还有用来记录缓慢变化维数据的拉链表（缓慢变化全量效率低），拉链表记录每条数据的生命周期，一旦生命周期结束就会产生一条新的记录，当前日期作为老记录的结束日期和新记录的开始日期，未过期的记录结束日期为9999-12-31

​	**dwd层**存放的是事实表，设计事实表主要找原子操作，加购，下单，支付等

- 设计事务型事实表
  - 选择业务过程 ：选择我们感兴趣的业务过程，也就是指标所需要的
  
  - 声明粒度：粒度就是指一行数据代表什么含义，事实表一般保持最小粒度
  
  - 确认维度： 确定指标中所需要的 用户，商品，活动，优惠券等
  
  - 确认事实： 确定事实表度量值，可以累加的值，个数，次数，件数，金额等
  
  - 但是也有事务型事实表解决不了的情况，比如连续性或者存量型记录（购物车存量）需要用到周期快照事实表
  
- 周期快照事实表 

​		声明粒度：由采样周期和维度描述，故确定采样周期和维度后即可确定粒度。采样周期一般为一天

​		确认事实： 事实也可根据统计指标决定，例如指标为统计每个仓库中每种商品的库存，则事实为商品库存。

还有多个业务过程联合处理的记录无法描述，比如确认收货流程需要用到累积型快照事实表

- 累积快照事实表

  有多个业务过程，多个时间字段，每个时间对应一个业务过程的数据。例如：确认收货累积快照事实表。

1. 选择业务过程 ：选择一个业务流程中需要关联分析的多个关键业务过程，多个业务过程对应一张累积型快照事实表。
2. 声明粒度：粒度就是指一行数据代表什么含义，事实表一般保持最小粒度
3. 确认维度： 选择与各业务过程相关的维度，需要注意的是，每各业务过程均需要一个日期维度。
4. 确认事实：选择各业务过程的度量值。

​	DIM和DWD层还做了数据清洗，将核心字段为null的数据过滤掉

​	脱敏，将用户维度的隐私信息加密处理

​	采用压缩，减少磁盘占用snappy压缩





最后**构建指标体系**，就是对指标进行分析，整理出指标体系继而设计出汇总模型，构建出DWS层，整理指标体系的作用就是指标定义标准化，能够避免指标定义存在歧义，指标定义重复等问题。因为绝大部分的指标都可以用原子指标，派生指标，衍生指标去定义，当统计需求较多时，必然会有统计需求对应的派生指标相同的情况，这时，我们可以将这种公共的派生指标保存下来，存放在DWS层，设计DWS层的目的就是为了减少重复计算，提高数据复用性，一张汇总表保存的是**业务过程相同，粒度相同，统计周期相同**的多个派生指标。

**ADS**层指标

日活，周活，月活，留存，留存率，流失，回流，新增，转化率，7天内连续三天登录、连续三天下单，新增下单，新增支付，品牌复购率，（1，7，30日）订单数，订单人数，退单数，退单人数，退款率，各地区订单数，订单金额，领取优惠券，使用优惠券人数，热门商品，销量topn，收藏topn

派生指标=原子指标（业务过程+度量值+聚合逻辑）+统计周期+统计粒度+业务限定

下单总额（下单+金额+sum）+每日+省份+水杯

每日各省份水杯交易总额

最后我们将业务过程相同，粒度相同，统计周期相同的多个派生指标创建一张宽表，比如用户粒度加购最近1日表，最近一日加购次数，最近一日加购商品件数两个派生指标业务过程相同，统计周期相同，统计粒度相同，所以创建一张汇总宽表



连续三天下单，新增下单，新增支付，复购率，（1，7，30日）订单数，订单人数，退单数，退单人数，退款率，各地区订单数，订单金额，领取优惠券，使用优惠券人数，热门商品，销量topn，收藏topn



​		遇到的问题：在统计各地区订单总额时出现数据倾斜（昆山，苏州，上海，无锡）

​				解决：开启groupby.skewindata双重聚合,第一次将数据随机分布到reduce中进行局部聚合，第二次将结果按照key将数据分到reduce中进行最终的聚合

​				在统计加购到确认收货平均时长时出现数据倾斜，由于在最开始设计DWD层时未设计确认收货累积快照事实表，在做这个指标时会有大表join大表的情况

​				解决：左表加随机数，右表扩容，然后进行聚合



首日全量

首日全量同步的用户表加上开始日期和结束日期后作为初始的拉链表，开始日期为当日，结束日期为日期最大值，作为最新状态保存到9999分区
每日装载
把当日新增及变化用户表加上开始日期和结束日期作为用户变化表，然后和截止到前一天的最新状态合并，然后加一个标记列，把变化的记录对应的旧记录标记为2，其他的标记为1，然后将标记为2的数据结束日期更改为前一天，然后按照结束日期动态分区，最新状态为9999分区，旧记录进入各自结束日期的分区



#### 确认维度

根据业务过程所处的环境确定，把环境信息提取出来就是维度

